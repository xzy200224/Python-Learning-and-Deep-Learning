{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2098da78",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 线性代数\n",
    "\n",
    "标量由只有一个元素的张量表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44889577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:42.354657Z",
     "iopub.status.busy": "2023-08-18T07:01:42.353844Z",
     "iopub.status.idle": "2023-08-18T07:01:43.769394Z",
     "shell.execute_reply": "2023-08-18T07:01:43.768177Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "x + y, x * y, x / y, x**y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d82f481",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "向量可以被视为标量值组成的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5163ab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.774490Z",
     "iopub.status.busy": "2023-08-18T07:01:43.773987Z",
     "iopub.status.idle": "2023-08-18T07:01:43.781757Z",
     "shell.execute_reply": "2023-08-18T07:01:43.780603Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297e056d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "通过张量的索引来访问任一元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34dd7630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.786346Z",
     "iopub.status.busy": "2023-08-18T07:01:43.785939Z",
     "iopub.status.idle": "2023-08-18T07:01:43.793065Z",
     "shell.execute_reply": "2023-08-18T07:01:43.791986Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e1565a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "访问张量的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d469059b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.798087Z",
     "iopub.status.busy": "2023-08-18T07:01:43.797197Z",
     "iopub.status.idle": "2023-08-18T07:01:43.804049Z",
     "shell.execute_reply": "2023-08-18T07:01:43.802867Z"
    },
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d74f2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "只有一个轴的张量，形状只有一个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf9bf15e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.809543Z",
     "iopub.status.busy": "2023-08-18T07:01:43.808709Z",
     "iopub.status.idle": "2023-08-18T07:01:43.815762Z",
     "shell.execute_reply": "2023-08-18T07:01:43.814675Z"
    },
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ae596",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "通过指定两个分量$m$和$n$来创建一个形状为$m \\times n$的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1eac085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.820985Z",
     "iopub.status.busy": "2023-08-18T07:01:43.820088Z",
     "iopub.status.idle": "2023-08-18T07:01:43.828057Z",
     "shell.execute_reply": "2023-08-18T07:01:43.826957Z"
    },
    "origin_pos": 27,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20).reshape(5, 4)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66a0813",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "矩阵的转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "289523ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.833285Z",
     "iopub.status.busy": "2023-08-18T07:01:43.832377Z",
     "iopub.status.idle": "2023-08-18T07:01:43.839757Z",
     "shell.execute_reply": "2023-08-18T07:01:43.838656Z"
    },
    "origin_pos": 32,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8, 12, 16],\n",
       "        [ 1,  5,  9, 13, 17],\n",
       "        [ 2,  6, 10, 14, 18],\n",
       "        [ 3,  7, 11, 15, 19]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b49d3e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*对称矩阵*（symmetric matrix）$\\mathbf{A}$等于其转置：$\\mathbf{A} = \\mathbf{A}^\\top$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0eb414b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.845394Z",
     "iopub.status.busy": "2023-08-18T07:01:43.844475Z",
     "iopub.status.idle": "2023-08-18T07:01:43.852725Z",
     "shell.execute_reply": "2023-08-18T07:01:43.851678Z"
    },
    "origin_pos": 37,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 0, 4],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44cc700c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.857930Z",
     "iopub.status.busy": "2023-08-18T07:01:43.856978Z",
     "iopub.status.idle": "2023-08-18T07:01:43.864388Z",
     "shell.execute_reply": "2023-08-18T07:01:43.863329Z"
    },
    "origin_pos": 42,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B == B.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0e0f73",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "就像向量是标量的推广，矩阵是向量的推广一样，我们可以构建具有更多轴的数据结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f7227a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.869592Z",
     "iopub.status.busy": "2023-08-18T07:01:43.868624Z",
     "iopub.status.idle": "2023-08-18T07:01:43.876563Z",
     "shell.execute_reply": "2023-08-18T07:01:43.875497Z"
    },
    "origin_pos": 47,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f4616c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6c89bd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.881686Z",
     "iopub.status.busy": "2023-08-18T07:01:43.880912Z",
     "iopub.status.idle": "2023-08-18T07:01:43.891206Z",
     "shell.execute_reply": "2023-08-18T07:01:43.890082Z"
    },
    "origin_pos": 52,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "# 使用 B = A.clone() 而不是简单的 B = A，是因为简单的赋值语句只会创建一个指向原始张量的引用，而不是创建一个新的张量。\n",
    "B = A.clone()\n",
    "A, A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdea0f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "两个矩阵的按元素乘法称为*Hadamard积*（Hadamard product）（数学符号$\\odot$）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1efe4855",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.896102Z",
     "iopub.status.busy": "2023-08-18T07:01:43.895401Z",
     "iopub.status.idle": "2023-08-18T07:01:43.903331Z",
     "shell.execute_reply": "2023-08-18T07:01:43.902251Z"
    },
    "origin_pos": 57,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.],\n",
       "        [ 16.,  25.,  36.,  49.],\n",
       "        [ 64.,  81., 100., 121.],\n",
       "        [144., 169., 196., 225.],\n",
       "        [256., 289., 324., 361.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "587335a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.908593Z",
     "iopub.status.busy": "2023-08-18T07:01:43.907694Z",
     "iopub.status.idle": "2023-08-18T07:01:43.916299Z",
     "shell.execute_reply": "2023-08-18T07:01:43.915117Z"
    },
    "origin_pos": 62,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "a + X, (a * X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89993c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "计算其元素的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32507943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.921298Z",
     "iopub.status.busy": "2023-08-18T07:01:43.920499Z",
     "iopub.status.idle": "2023-08-18T07:01:43.929213Z",
     "shell.execute_reply": "2023-08-18T07:01:43.928096Z"
    },
    "origin_pos": 67,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor(6.))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4, dtype=torch.float32)\n",
    "x, x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c90279",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "表示任意形状张量的元素和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e0cd60f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.934058Z",
     "iopub.status.busy": "2023-08-18T07:01:43.933342Z",
     "iopub.status.idle": "2023-08-18T07:01:43.940936Z",
     "shell.execute_reply": "2023-08-18T07:01:43.939832Z"
    },
    "origin_pos": 72,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), tensor(190.))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, A.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cc5703",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "指定张量沿哪一个轴来通过求和降低维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9420cc92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.946290Z",
     "iopub.status.busy": "2023-08-18T07:01:43.945345Z",
     "iopub.status.idle": "2023-08-18T07:01:43.953195Z",
     "shell.execute_reply": "2023-08-18T07:01:43.952092Z"
    },
    "origin_pos": 77,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([40., 45., 50., 55.]), torch.Size([4]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis0 = A.sum(axis=0)\n",
    "A_sum_axis0, A_sum_axis0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50e59a41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.958180Z",
     "iopub.status.busy": "2023-08-18T07:01:43.957431Z",
     "iopub.status.idle": "2023-08-18T07:01:43.965338Z",
     "shell.execute_reply": "2023-08-18T07:01:43.964267Z"
    },
    "origin_pos": 82,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis1 = A.sum(axis=1)\n",
    "A_sum_axis1, A_sum_axis1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1ba976a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.970587Z",
     "iopub.status.busy": "2023-08-18T07:01:43.969706Z",
     "iopub.status.idle": "2023-08-18T07:01:43.977405Z",
     "shell.execute_reply": "2023-08-18T07:01:43.976340Z"
    },
    "origin_pos": 87,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(190.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a33400",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "一个与求和相关的量是*平均值*（mean或average）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d901892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.982674Z",
     "iopub.status.busy": "2023-08-18T07:01:43.981742Z",
     "iopub.status.idle": "2023-08-18T07:01:43.990067Z",
     "shell.execute_reply": "2023-08-18T07:01:43.988981Z"
    },
    "origin_pos": 92,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9.5000), tensor(9.5000))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(), A.sum() / A.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65c39834",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:43.995223Z",
     "iopub.status.busy": "2023-08-18T07:01:43.994254Z",
     "iopub.status.idle": "2023-08-18T07:01:44.003242Z",
     "shell.execute_reply": "2023-08-18T07:01:44.002162Z"
    },
    "origin_pos": 97,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100420c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "计算总和或均值时保持轴数不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cc17274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:44.008471Z",
     "iopub.status.busy": "2023-08-18T07:01:44.007568Z",
     "iopub.status.idle": "2023-08-18T07:01:44.016007Z",
     "shell.execute_reply": "2023-08-18T07:01:44.014845Z"
    },
    "origin_pos": 102,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.],\n",
       "        [22.],\n",
       "        [38.],\n",
       "        [54.],\n",
       "        [70.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keepdims=True 参数用于指示在结果张量中保留原始维度，即将求和后的维度保持为原始张量的维度。\n",
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3055e67",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "通过广播将`A`除以`sum_A`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63a5b49d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:44.020992Z",
     "iopub.status.busy": "2023-08-18T07:01:44.020591Z",
     "iopub.status.idle": "2023-08-18T07:01:44.028726Z",
     "shell.execute_reply": "2023-08-18T07:01:44.027663Z"
    },
    "origin_pos": 107,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
       "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
       "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
       "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
       "        [0.2286, 0.2429, 0.2571, 0.2714]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / sum_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5074bd29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "某个轴计算`A`元素的累积总和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27eb9655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:44.033849Z",
     "iopub.status.busy": "2023-08-18T07:01:44.033115Z",
     "iopub.status.idle": "2023-08-18T07:01:44.041281Z",
     "shell.execute_reply": "2023-08-18T07:01:44.040150Z"
    },
    "origin_pos": 112,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  6.,  8., 10.],\n",
       "        [12., 15., 18., 21.],\n",
       "        [24., 28., 32., 36.],\n",
       "        [40., 45., 50., 55.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dfe953",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "计算两个 1 维张量的点积，点积是相同位置的按元素乘积的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7840d740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:44.045914Z",
     "iopub.status.busy": "2023-08-18T07:01:44.045514Z",
     "iopub.status.idle": "2023-08-18T07:01:44.058183Z",
     "shell.execute_reply": "2023-08-18T07:01:44.057040Z"
    },
    "origin_pos": 117,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(4, dtype = torch.float32)\n",
    "x, y, torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a3bdc",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "我们可以通过执行按元素乘法，然后进行求和来表示两个向量的点积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dadc2a45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:44.062812Z",
     "iopub.status.busy": "2023-08-18T07:01:44.062422Z",
     "iopub.status.idle": "2023-08-18T07:01:44.070070Z",
     "shell.execute_reply": "2023-08-18T07:01:44.068907Z"
    },
    "origin_pos": 122,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4bb53f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "矩阵向量积$\\mathbf{A}\\mathbf{x}$是一个长度为$m$的列向量，\n",
    "其第$i$个元素是点积$\\mathbf{a}^\\top_i \\mathbf{x}$\n",
    "\n",
    "注意，A的列维数（沿轴1的长度）必须与x的维数（其长度）相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62c6809c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:44.075294Z",
     "iopub.status.busy": "2023-08-18T07:01:44.074579Z",
     "iopub.status.idle": "2023-08-18T07:01:44.082607Z",
     "shell.execute_reply": "2023-08-18T07:01:44.081496Z"
    },
    "origin_pos": 130,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, x.shape, torch.mv(A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a86f222",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "我们可以将矩阵-矩阵乘法$\\mathbf{AB}$看作简单地执行$m$次矩阵-向量积，并将结果拼接在一起，形成一个$n \\times m$矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e3efc16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:44.087651Z",
     "iopub.status.busy": "2023-08-18T07:01:44.086870Z",
     "iopub.status.idle": "2023-08-18T07:01:44.095375Z",
     "shell.execute_reply": "2023-08-18T07:01:44.094329Z"
    },
    "origin_pos": 135,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.,  6.],\n",
       "        [22., 22., 22.],\n",
       "        [38., 38., 38.],\n",
       "        [54., 54., 54.],\n",
       "        [70., 70., 70.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.ones(4, 3)\n",
    "torch.mm(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061e98c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$L_2$*范数*是向量元素平方和的平方根：\n",
    "$$\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f829c100",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:44.100377Z",
     "iopub.status.busy": "2023-08-18T07:01:44.099628Z",
     "iopub.status.idle": "2023-08-18T07:01:44.107745Z",
     "shell.execute_reply": "2023-08-18T07:01:44.106642Z"
    },
    "origin_pos": 140,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b36a33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$L_1$范数，它表示为向量元素的绝对值之和：\n",
    "$$\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n \\left|x_i \\right|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01356584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:44.143775Z",
     "iopub.status.busy": "2023-08-18T07:01:44.142900Z",
     "iopub.status.idle": "2023-08-18T07:01:44.151418Z",
     "shell.execute_reply": "2023-08-18T07:01:44.150335Z"
    },
    "origin_pos": 145,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(u).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a43fb6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "矩阵\n",
    "的*Frobenius范数*（Frobenius norm）是矩阵元素平方和的平方根：\n",
    "$$\\|\\mathbf{X}\\|_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n x_{ij}^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a8792ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T07:01:44.156452Z",
     "iopub.status.busy": "2023-08-18T07:01:44.155694Z",
     "iopub.status.idle": "2023-08-18T07:01:44.163608Z",
     "shell.execute_reply": "2023-08-18T07:01:44.162540Z"
    },
    "origin_pos": 150,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.ones((4, 9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee19aafa",
   "metadata": {},
   "source": [
    "### 练习\n",
    "1.证明一个矩阵的转置的转置是自身\n",
    "\n",
    "2.给出两个矩阵证明“它们转置的和”等于“它们和的转置”\n",
    "\n",
    "3.给定任意方阵，A+A^T总是对称的吗?\n",
    "\n",
    "4.本节中定义了形状(2,3,4)的张量X。len(X)的输出结果是什么？\n",
    "\n",
    "5.对于任意形状的张量X,len(X)是否总是对应于X特定轴的长度?这个轴是什么?\n",
    "\n",
    "6.运行A/A.sum(axis=1)，看看会发生什么。请分析一下原因？\n",
    "\n",
    "7.考虑一个具有形状(2,3,4)的张量，在轴0、1、2上的求和输出是什么形状?\n",
    "\n",
    "8.为linalg.norm函数提供3个或更多轴的张量，并观察其输出。对于任意形状的张量这个函数计算得到什么?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbc66e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "torch.all() 主要用于检查张量中所有元素是否满足某个条件\n",
    "torch.eq(input, other) 将比较输入张量 input 和另一个张量 other 的每个对应位置上的元素是否相等\n",
    "\"\"\"\n",
    "import torch \n",
    "A = torch.randn((2, 3))\n",
    "A_transpose = A.T.T\n",
    "is_equal = torch.all(torch.eq(A, A_transpose))\n",
    "is_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07e519f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.randn((2, 3))\n",
    "(B + A).T == A.T + B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7c83bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 3, 4]), 24)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.randn((2, 3, 4))\n",
    "len(C), C.shape, C.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4ed6403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]),\n",
       " tensor([ 6, 15, 24]),\n",
       " tensor([[0.1667, 0.1333, 0.1250],\n",
       "         [0.6667, 0.3333, 0.2500],\n",
       "         [1.1667, 0.5333, 0.3750]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "D, D.sum(axis=1), D / D.sum(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7844aa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2632, -0.5582,  2.0734,  0.7030],\n",
       "         [-3.4219, -1.0620, -0.4057,  2.0965],\n",
       "         [ 0.6521,  0.6359, -0.8435, -1.2390]]),\n",
       " tensor([[-2.1931, -1.7161,  0.7193, -0.0055],\n",
       "         [-0.3136,  0.7317,  0.1048,  1.5660]]),\n",
       " tensor([[ 1.9951, -3.4973, -1.6932],\n",
       "         [ 0.4861,  0.7041,  0.8986]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.sum(axis = 0), C.sum(axis = 1), C.sum(axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e347a",
   "metadata": {},
   "source": [
    "torch.linalg.norm() 和 torch.norm() 都是 PyTorch 中计算张量范数的函数，但它们之间有一些区别。\n",
    "\n",
    "功能范围不同：\n",
    "\n",
    "torch.linalg.norm() 主要用于计算线性代数中的矩阵范数，例如 Frobenius 范数、L1 范数和 L2 范数等。\n",
    "torch.norm() 则更为通用，可以计算张量的各种范数，如向量范数、矩阵范数、以及高阶张量的范数。\n",
    "输入参数不同：\n",
    "\n",
    "torch.linalg.norm() 的参数包括输入张量 input 和可选的 ord 和 dim。其中，ord 用于指定计算的范数类型，dim 用于指定在哪个维度上进行计算，默认是计算整个张量的范数。\n",
    "torch.norm() 的参数包括输入张量 input 和可选的 p、dim、keepdim 和 dtype。其中，p 用于指定计算的范数类型，dim 用于指定在哪个维度上进行计算，默认是计算整个张量的范数，keepdim 用于保持输出张量的维度和输入张量相同，dtype 用于指定输出张量的数据类型。\n",
    "数据类型支持不同：\n",
    "\n",
    "torch.linalg.norm() 在输入张量为浮点型和复数型时可用。\n",
    "torch.norm() 在输入张量为整型、浮点型和复数型时均可用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec3a4d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default L2 Norm:\n",
      "tensor(9.5394)\n",
      "\n",
      "L2 Norm along axis 1:\n",
      "tensor([3.7417, 8.7750])\n",
      "\n",
      "L1 Norm along axis 0:\n",
      "tensor([5., 7., 9.])\n",
      "\n",
      "Frobenius Norm of the matrix:\n",
      "tensor(9.5394)\n"
     ]
    }
   ],
   "source": [
    "# 示例张量\n",
    "A = torch.tensor([[1., 2, 3], [4, 5, 6]])\n",
    "\n",
    "# 计算默认情况下的L2范数（向量的欧几里得范数）\n",
    "norm_1 = torch.linalg.norm(A)\n",
    "print(\"Default L2 Norm:\")\n",
    "print(norm_1)\n",
    "\n",
    "# 计算每行的L2范数\n",
    "norm_2 = torch.linalg.norm(A, dim=1)\n",
    "print(\"\\nL2 Norm along axis 1:\")\n",
    "print(norm_2)\n",
    "\n",
    "# 计算每列的L1范数\n",
    "norm_3 = torch.linalg.norm(A, dim=0, ord=1)\n",
    "print(\"\\nL1 Norm along axis 0:\")\n",
    "print(norm_3)\n",
    "\n",
    "# 计算整个矩阵的Frobenius范数\n",
    "norm_4 = torch.linalg.norm(A, ord='fro')\n",
    "print(\"\\nFrobenius Norm of the matrix:\")\n",
    "print(norm_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985422a6",
   "metadata": {},
   "source": [
    "### 解答\n",
    "在 PyTorch 中，copy 和 clone 都是用于创建张量副本的函数，但它们在底层实现上有一些不同。\n",
    "\n",
    "内存分配方式不同：\n",
    "\n",
    "copy 函数会为新的张量分配新的内存空间，将原始张量的值复制到新的张量中。\n",
    "clone 函数则会在新的张量中分配新的内存空间，并将原始张量的值和计算图都复制到新的张量中。这意味着，与 copy 不同，clone 复制的新张量与原始张量共享计算图，因此它可以保留梯度信息。\n",
    "参数设置不同：\n",
    "\n",
    "copy 函数不需要任何参数，它会直接返回一个新的张量副本。\n",
    "clone 函数可以设置两个可选参数：memory_format 和 non_blocking。其中，memory_format 用于指定新张量的存储格式，non_blocking 则用于设置是否将张量复制到非阻塞式内存中。\n",
    "使用场景不同：\n",
    "\n",
    "copy 通常用于需要创建新的张量副本并且不需要保留梯度信息的情况，如数据处理、拷贝数据到其他设备等。\n",
    "clone 则通常用于需要创建新的张量副本并且需要保留梯度信息的情况，如在计算图中进行反向传播时。"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "required_libs": [],
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
